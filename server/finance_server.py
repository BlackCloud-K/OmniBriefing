import concurrent.futures
from mcp.server.fastmcp import FastMCP
import yfinance as yf
import json
from datetime import datetime
from groq import Groq
import requests
import os
from dotenv import load_dotenv
from bs4 import BeautifulSoup
import trafilatura
from time import sleep

# 1. åˆå§‹åŒ–ç¯å¢ƒ
load_dotenv()
# æ³¨æ„ï¼šä¿æŒä½ åŸæœ‰çš„è®¾ç½®ï¼Œä½¿ç”¨ OPENAI_API_KEY å˜é‡åè¯»å– Groq Key
groq_api_key = os.getenv("OPENAI_API_KEY") 
if not groq_api_key:
    print("Warning: OPENAI_API_KEY (for Groq) not found.")

groq_client = Groq(api_key=groq_api_key)
mcp = FastMCP("finance")

# === ğŸŒŸ æ ¸å¿ƒå‡çº§: å…¨å±€ä¼šè¯çŠ¶æ€ (The Session State) ===
# è¿™å°±åƒä¸€ä¸ªâ€œè´­ç‰©è½¦â€ï¼Œç”¨æ¥æš‚å­˜ Agent æŒ‘é€‰çš„æ•°æ®
SESSION_STATE = {
    "prices": {},       # å­˜è‚¡ä»·: {"NVDA": {...}, "AAPL": {...}}
    "raw_news": [],     # å­˜åŸå§‹æ–°é—»: [{"id": 0, "title": "...", "url": "...", "ticker": "..."}]
    "summaries": []     # å­˜æ€»ç»“å¥½çš„æ–°é—»: [{"id": 0, "summary": "..."}]
}

def _reset_session():
    """æ¸…ç©ºè´­ç‰©è½¦ï¼Œå¼€å§‹æ–°çš„ä¸€è½®åˆ†æ"""
    SESSION_STATE["prices"] = {}
    SESSION_STATE["raw_news"] = []
    SESSION_STATE["summaries"] = []

# === 2. çˆ¬è™«å·¥å…· (ä¿ç•™ä½ ç°æœ‰çš„ Trafilatura é€»è¾‘) ===
def _fetch_text(url: str) -> str:
    """
    ä½¿ç”¨ trafilatura åº“è¿›è¡Œæœ¬åœ°æ™ºèƒ½æå–ã€‚
    """
    try:
        # 1. ä¸‹è½½ (å®ƒä¼šè‡ªåŠ¨å¤„ç† User-Agent å’Œç®€å•çš„åçˆ¬é‡è¯•)
        downloaded = trafilatura.fetch_url(url)
        
        if not downloaded:
            return "Error: Failed to download page."
            
        # 2. æå– (æ™ºèƒ½è¯†åˆ«æ­£æ–‡ï¼Œå¿½ç•¥ä¾§è¾¹æ å’Œå¹¿å‘Š)
        text = trafilatura.extract(
            downloaded, 
            include_comments=False, 
            include_tables=True,
            no_fallback=True
        )
        
        if not text or len(text) < 200:
            return "Error: Extracted content empty or too short."
            
        return text

    except Exception as e:
        return f"Error: {str(e)}"

# ==========================================
# ğŸ›’ Tool 1: å­˜è‚¡ä»· (Add Prices to Cart)
# ==========================================
@mcp.tool()
def fetch_and_store_prices(tickers: list[str], prepost: bool = True) -> str:
    """
    Fetch and store stock prices for given ticker symbols.
    
    Args:
        tickers: A list of stock ticker symbols (e.g., ["AAPL", "NVDA", "TSLA"]).
        prepost: Optional boolean (default: False). If True, includes pre-market and post-market data.
                Set to True if you need extended hours trading data.
    """
    _reset_session() # è§†ä¸ºæ–°ä¼šè¯å¼€å§‹ï¼Œæ¸…ç©ºæ—§æ•°æ®
    
    if not tickers:
        return "No tickers provided."

    # å®šä¹‰å•ä¸ªæŠ“å–é€»è¾‘ (å¤ç”¨ä½ ä¹‹å‰çš„é€»è¾‘)
    def fetch_single_ticker(ticker):
        try:
            stock = yf.Ticker(ticker)
            # ç­–ç•¥: ä¼˜å…ˆå– 1å¤©ï¼Œå¦‚æœæ˜¯å‘¨æœ«/ä¼‘å¸‚å–ä¸åˆ°ï¼Œåˆ™å›é€€å– 5å¤©
            hist = stock.history(period="1d", interval="1h", prepost=prepost)
            if hist.empty:
                hist = stock.history(period="5d", interval="1h", prepost=prepost)
            
            if hist.empty:
                return {"symbol": ticker, "status": "No Data", "error": "Market Closed/No Data"}
            
            current_price = hist['Close'].iloc[-1]
            
            # è®¡ç®—æ¶¨è·Œå¹…
            last_date = hist.index[-1].date()
            day_data = hist[hist.index.date == last_date]
            
            if not day_data.empty:
                open_price = day_data['Open'].iloc[0]
            else:
                open_price = hist['Open'].iloc[-1]
            
            info = {}
            try: info = stock.info
            except: pass

            prev_close = info.get('previousClose')
            base_price = prev_close if prev_close else open_price
            
            change_percent = ((current_price - base_price) / base_price) * 100
            name = info.get('shortName', info.get('longName', ticker))
            
            return {
                "symbol": ticker,
                "name": name,
                "price": round(current_price, 2),
                "change": round(change_percent, 2),
                "last_updated": datetime.now().strftime("%Y-%m-%d %H:%M:%S"),
                "status": 'Active',
                "price_history": hist['Close']
            }
        except Exception as e:
            return {"symbol": ticker, "status": "Error", "error": str(e)}

    # å¹¶å‘æ‰§è¡Œ
    results_summary = []
    max_workers = min(len(tickers), 10)
    
    with concurrent.futures.ThreadPoolExecutor(max_workers=max_workers) as executor:
        future_to_ticker = {executor.submit(fetch_single_ticker, t): t for t in tickers}
        
        for future in concurrent.futures.as_completed(future_to_ticker):
            data = future.result()
            ticker = data["symbol"]
            
            # å­˜å…¥å…¨å±€ Session
            SESSION_STATE["prices"][ticker] = data
            
            # ç”Ÿæˆç®€æŠ¥å­—ç¬¦ä¸²è¿”å›ç»™ Client
            if data["status"] == "Active":
                results_summary.append(f"{ticker}: {data['change']}%")
            else:
                results_summary.append(f"{ticker}: {data['status']}")
            
    return f"Prices stored in server. Quick View: {', '.join(results_summary)}"

# ==========================================
# ğŸ›’ Tool 2: æŸ¥æ–°é—»èœå• (Search & Menu)
# ==========================================
@mcp.tool()
def search_news_options(tickers: list[str], limit: int = 4) -> str:
    """
    Search and retrieve news article options for given stock tickers.
    
    Args:
        tickers: A list of stock ticker symbols (e.g., ["AAPL", "NVDA", "TSLA"]).
                News will be searched for each ticker symbol provided.
        limit: Optional integer (No more than 4). Maximum number of news articles to retrieve per ticker.
               Higher values return more articles but may take longer to process.
    """
    if not tickers:
        return "No tickers provided."
        
    SESSION_STATE["raw_news"] = [] # æ¸…ç©ºæ—§æ–°é—»åˆ—è¡¨
    global_index = 0
    menu_output = []
    
    # ç”¨äºå»é‡çš„é›†åˆï¼šè·Ÿè¸ªå·²è§è¿‡çš„ URL å’Œæ ‡é¢˜
    seen_urls = set()
    seen_titles = set()
    
    # å†…éƒ¨å‡½æ•°ï¼šè·å–å•åªè‚¡ç¥¨æ–°é—»
    def fetch_single_news(ticker):
        try:
            stock = yf.Ticker(ticker)
            news_list = stock.news
            if not news_list: return []
            
            valid_items = []
            safe_limit = min(limit, len(news_list))
            
            for item in news_list[:safe_limit]:
                # å¤ç”¨ä½ çš„è§£æé€»è¾‘
                data = item.get('content', item)
                title = data.get('title', 'No Title')
                
                # æå–é“¾æ¥
                link = None
                if 'clickThroughUrl' in data and data['clickThroughUrl']:
                    link = data['clickThroughUrl'].get('url')
                if not link and 'canonicalUrl' in data and data['canonicalUrl']:
                    link = data['canonicalUrl'].get('url')
                if not link:
                    link = data.get('link') or data.get('url')
                    
                if link and title != "No Title":
                    valid_items.append({"ticker": ticker, "title": title, "url": link})
            return valid_items
        except:
            return []

    # å¹¶å‘æŠ“å–æ–°é—»å…ƒæ•°æ®
    with concurrent.futures.ThreadPoolExecutor(max_workers=min(len(tickers), 10)) as executor:
        future_to_ticker = {executor.submit(fetch_single_news, t): t for t in tickers}
        
        for future in concurrent.futures.as_completed(future_to_ticker):
            items = future.result()
            for item in items:
                # å»é‡æ£€æŸ¥ï¼šå¦‚æœ URL æˆ–æ ‡é¢˜å·²å­˜åœ¨ï¼Œåˆ™è·³è¿‡
                url = item["url"]
                title = item["title"]
                
                # æ ‡å‡†åŒ– URL å’Œæ ‡é¢˜ç”¨äºæ¯”è¾ƒï¼ˆå»é™¤é¦–å°¾ç©ºæ ¼ï¼Œè½¬ä¸ºå°å†™ï¼‰
                url_normalized = url.strip().lower() if url else ""
                title_normalized = title.strip().lower() if title else ""
                
                # å¦‚æœ URL æˆ–æ ‡é¢˜å·²å­˜åœ¨ï¼Œè·³è¿‡è¿™æ¡æ–°é—»
                if url_normalized in seen_urls or title_normalized in seen_titles:
                    continue
                
                # æ·»åŠ åˆ°å·²è§é›†åˆ
                if url_normalized:
                    seen_urls.add(url_normalized)
                if title_normalized:
                    seen_titles.add(title_normalized)
                
                # å­˜å…¥å…¨å±€åˆ—è¡¨ï¼Œåˆ†é… ID
                entry = {
                    "id": global_index,
                    "ticker": item["ticker"],
                    "title": item["title"],
                    "url": item["url"]
                }
                SESSION_STATE["raw_news"].append(entry)
                
                # ç”Ÿæˆèœå•é¡¹
                menu_output.append(f"[{global_index}] {item['ticker']} | {item['title']}")
                global_index += 1
    
    if not menu_output:
        return "No news found."
        
    return "Available News Options (Select by ID):\n" + "\n".join(menu_output)

# ==========================================
# ğŸ›’ Tool 3: é€‰æ–°é—»å¹¶æ€»ç»“ (Checkout)
# ==========================================
@mcp.tool()
def summarize_selected_indices(indices: list[int], focus_instruction: str = "General summary") -> str:
    """
    Fetch and summarize selected news articles by their indices.
    
    Args:
        indices: A list of integer indices corresponding to news articles from search_news_options.
                For example, [0, 2, 5] will summarize the articles at positions 0, 2, and 5.
                Indices must be valid (within the range of available news articles).
        focus_instruction: Optional string (default: "General summary"). Custom instruction for the AI
                          summarization process.
    """
    selected_items = []
    # éªŒè¯ ID
    for idx in indices:
        if 0 <= idx < len(SESSION_STATE["raw_news"]):
            selected_items.append(SESSION_STATE["raw_news"][idx])
            
    if not selected_items:
        return "Invalid indices provided."

    print(f"Summarizing {len(selected_items)} selected articles...")

    # å†…éƒ¨å¤„ç†å‡½æ•°
    def process_item(item):
        url = item['url']
        ticker = item['ticker']
        
        # 1. æŠ“å–
        raw_text = _fetch_text(url)
        if not raw_text or raw_text.startswith("Error"):
            return {
                "id": item['id'],
                "ticker": ticker,
                "summary": f"Failed to fetch content: {raw_text}"
            }

        # 2. æ€»ç»“ (ä½¿ç”¨ Groq 17B)
        system_prompt = (
            "You are a high-efficiency financial news extractor. "
            "Compress the article content into strict format:\n"
            "### 1. EXECUTIVE SUMMARY\n"
            "### 2. HARD DATA (Numbers/Dates)\n"
            "### 3. KEY QUOTES\n"
            "Constraints: Under 400 words. Be telegraphic."
        )
        user_prompt = f"User INSTRUCTION: {focus_instruction}\n\nCONTENT:\n{raw_text[:12000]}"

        try:
            chat_completion = groq_client.chat.completions.create(
                messages=[
                    {"role": "system", "content": system_prompt},
                    {"role": "user", "content": user_prompt}
                ],
                model="meta-llama/llama-4-scout-17b-16e-instruct",
                temperature=0.1,
            )
            summary = chat_completion.choices[0].message.content
            return {
                "id": item['id'],
                "ticker": ticker,
                "title": item['title'],
                "summary": summary
            }
        except Exception as e:
            return {"id": item['id'], "ticker": ticker, "summary": f"Error: {str(e)}"}

    # å¹¶å‘æ€»ç»“
    new_summaries = []
    with concurrent.futures.ThreadPoolExecutor(max_workers=5) as executor:
        futures = [executor.submit(process_item, item) for item in selected_items]
        for future in concurrent.futures.as_completed(futures):
            new_summaries.append(future.result())
            
    # å­˜å…¥ Session (è¿½åŠ æ¨¡å¼)
    SESSION_STATE["summaries"].extend(new_summaries)
    
    # è¿”å› JSON ç»™ Agentï¼Œæ–¹ä¾¿å®ƒå†³å®šä¸‹ä¸€æ­¥
    return json.dumps(new_summaries, ensure_ascii=False)

# ==========================================
# ğŸ›’ Tool 4: åˆ é™¤æ–°é—» (Remove News)
# ==========================================
@mcp.tool()
def remove_news_summaries(indices: list[int]) -> str:
    """
    Remove news summaries by their indices and return remaining indices.
    
    Args:
        indices: A list of integer indices to remove from stored news summaries.
                These indices correspond to the 'id' field in the summaries.
    
    Returns:
        A JSON string containing the list of remaining summary indices after removal.
    """
    if not indices:
        return json.dumps([item['id'] for item in SESSION_STATE["summaries"]], ensure_ascii=False)
    
    # åˆ é™¤æŒ‡å®š indices çš„æ–°é—»
    indices_to_remove = set(indices)
    SESSION_STATE["summaries"] = [
        item for item in SESSION_STATE["summaries"] 
        if item['id'] not in indices_to_remove
    ]
    
    # è¿”å›å‰©ä½™ indices
    remaining_indices = [item['id'] for item in SESSION_STATE["summaries"]]
    return json.dumps(remaining_indices, ensure_ascii=False)

# ==========================================
# ğŸ›’ Tool 5: å¯¼å‡ºæŠ¥å‘Š (Export)
# ==========================================
@mcp.tool()
def export_final_report() -> str:
    """
    Generate a final Markdown-formatted market report.
    
    Args:
        (No parameters)
    """
    sleep(50)
    md = "# Daily Market Pulse\n\n"
    
    # 1. è‚¡ä»·éƒ¨åˆ†
    md += "## Market Data\n"
    for ticker, data in SESSION_STATE["prices"].items():
        if data.get("status") == "Active":
            # 1. åŸºç¡€ä¿¡æ¯
            md += f"- **{ticker}**: {data['name']} ${data['price']} ({data['change']}%)\n"
            
            # 2. æ¸…æ´—å¹¶æ ¼å¼åŒ–åˆ†æ—¶æ•°æ® (Intraday Trend)
            history = data.get("price_history")
            
            # æ£€æŸ¥ history æ˜¯å¦æ˜¯ Pandas Series (å› ä¸ºæœ‰æ—¶å€™å¯èƒ½å­˜æˆ list)
            if hasattr(history, 'index') and not history.empty:
                # åˆ—è¡¨æ¨å¯¼å¼ï¼šåªå– "æ—¶:åˆ†" å’Œ "ä»·æ ¼"
                trend_points = [
                    f"{t.strftime('%H:%M')}:${p:.2f}" 
                    for t, p in zip(history.index, history.values)
                ]
                # ç”¨ç®­å¤´è¿æ¥ï¼Œæ—¢ç´§å‡‘åˆç›´è§‚
                trend_line = " â†’ ".join(trend_points)
                md += f"  - *Price Trend*: {trend_line}\n"
        else:
            md += f"- **{ticker}**: {data.get('status')}\n"
            
    # 2. æ–°é—»éƒ¨åˆ†
    md += "\n## Key Developments\n"
    if not SESSION_STATE["summaries"]:
        md += "(No news selected)\n"
    
    for item in SESSION_STATE["summaries"]:
        md += f"\n### [{item['ticker']}] {item.get('title', 'News')}\n"
        md += f"{item['summary']}\n"
        md += f"*(Ref ID: {item['id']})*\n"
        
    return md

if __name__ == "__main__":
    mcp.run()